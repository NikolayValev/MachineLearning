{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nikolay Valev\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import accuracy_score\n",
    "mnist = fetch_openml('mnist_784', version=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into a training set, a validation set, and a test set using the ratio\n",
    "5 : 1 : 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/7, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=1/6, random_state=1) # 0.25 x 0.8 = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000,)\n",
      "(10000, 784)\n",
      "(10000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9689\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "forest_clf = RandomForestClassifier(n_estimators=500,random_state=42)\n",
    "forest_clf.fit(X_train, y_train)\n",
    "y_pred_rf = forest_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# bagging classifier\n",
    "bagging_clf = BaggingClassifier(n_estimators=500,\n",
    "                          max_samples=100, bootstrap=True, random_state=42)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "Bagging_pred = bagging_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, Bagging_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8658\n"
     ]
    }
   ],
   "source": [
    "dtree_clf = DecisionTreeClassifier(random_state=42)\n",
    "dtree_clf.fit(X_train, y_train)\n",
    "y_pred_tree = dtree_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_tree))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the classifiers into an ensemble on the validation set using hard voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9331\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('bg', bagging_clf), ('rf', forest_clf), ('dt', dtree_clf)],\n",
    "    voting='hard')  # hard voting\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Does the ensemble outperform the individual classifiers?\n",
    "The voting classifier which has accuracy of 0.9457  performs better than all the individual classifiers except random forest classifier which has accuracy of 0.97 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Next remove the individual classifier with the smallest accuracy score.\n",
    "Bagging Classifier has accuracy of  0.842 making it the worst performing one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('dt', DecisionTreeClassifier(random_state=42)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(n_estimators=500,\n",
       "                                                     random_state=42))])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('dt', dtree_clf), ('rf', forest_clf)],\n",
    "voting='hard')\n",
    "voting_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Now combine the classifiers into an ensemble on the test data using hard voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9208\n"
     ]
    }
   ],
   "source": [
    "y_pred = voting_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. How much better does it perform compared to the individual classifiers? Comment on your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the bagging classifier is removed from the ensemble, the voting classifier outperforms the\n",
    "decision tree classifier (0.8658) but not the random forest classifier (0.9689).The voting\n",
    "classifier accuracy score decreased to 0.9208 from 0.9331"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4edf81528f27573aba80c4a2f996bd4f26027e917223287f3cada8b77132d7c8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
